# ET-NeuralCast: Deep Learning Architecture Specification

## 1. Overview
The **ET-NeuralCast** system employs a **Conditional Generative Adversarial Network (cGAN)** framework. 
*   **Generator ($G$)**: A **U-Net** based architecture responsible for producing the forecast (Precipitation/Temperature maps).
*   **Discriminator ($D$)**: A **PatchGAN** classifier responsible for distinguishing between real historical weather patterns and the forecasts generated by $G$.

---

## 2. The Generator: U-Net
The Generator takes large-scale climate drivers ($X$) and outputs local precipitation fields ($Y$).

### 2.1. Encoder (Contraction Path)
The encoder extracts hierarchical features from the input tensor.
*   **Input**: Tensor of shape $(B, C_{in}, H, W)$. 
    *   $C_{in}$: Number of channels (SST, Wind, Humidity, etc. ~10-20 channels).
    *   Resolution: e.g., $64 \times 64$ or $128 \times 128$ (depending on regridding).
*   **Blocks**: 4 Downsampling Steps.
    *   Each step: `Conv2d` (kernel=4, stride=2, padding=1) $\to$ `BatchNom` $\to$ `LeakyReLU(0.2)`.
    *   Doubles the number of filters ($64 \to 128 \to 256 \to 512$).
    *   Halves spatial dimensions.

### 2.2. Bottleneck
*   The deepest layer connecting Encoder and Decoder.
*   `Conv2d` (512 $\to$ 512) $\to$ `ReLU` $\to$ `Dropout(0.5)`.
*   Captures the most abstract, compressed representation of the climate state (e.g., "El Ni√±o state").

### 2.3. Decoder (Expansion Path)
Recovers spatial resolution while injecting details from the Encoder via Skip Connections.
*   **Blocks**: 4 Upsampling Steps.
    *   Each step: `ConvTranspose2d` (kernel=4, stride=2, padding=1) $\to$ `BatchNorm` $\to$ `ReLU` $\to$ `Dropout` (optional in first few layers).
    *   **Skip Connection**: Concatenate output with the corresponding tensor from the Encoder.
    *   Halves filter count ($512 \to 256 \to 128 \to 64$).
*   **Output Layer**:
    *   `Conv2d` (64 $\to$ $C_{out}$), `Tanh` activation.
    *   $C_{out}$: 1 (Precipitation). Note: Tanh outputs [-1, 1], requiring the target data to be normalized to this range.

---

## 3. The Discriminator: PatchGAN
Standard GAN discriminators output a single scalar (Real/Fake). A **PatchGAN** outputs an $N \times N$ grid of probabilities, classifying *patches* of the image as real or fake. This enforces high-frequency "sharpness" and texture.

### 3.1. Architecture
*   **Input**: Concatenation of Input Condition ($X$) and Target/Prediction ($Y$).
*   **Layers**:
    1.  `Conv2d` (64 filters, stride=2) $\to$ `LeakyReLU`.
    2.  `Conv2d` (128 filters, stride=2) $\to$ `BatchNorm` $\to$ `LeakyReLU`.
    3.  `Conv2d` (256 filters, stride=2) $\to$ `BatchNorm` $\to$ `LeakyReLU`.
    4.  `Conv2d` (1 channel, stride=1).
*   **Output**: A grid (e.g., $16 \times 16$) where each pixel represents the validity of a region in the original image.

---

## 4. Loss Functions & Optimization

### 4.1. Adversarial Loss (GAN Loss)
Encourages the Generator to produce realistic outputs.
$$ \mathcal{L}_{GAN}(G, D) = \mathbb{E}_{x,y}[\log D(x, y)] + \mathbb{E}_{x,z}[\log(1 - D(x, G(x, z)))] $$

### 4.2. L1 Loss (Reconstruction Loss)
Encourages the Generator to capture the ground truth structure and low frequencies.
$$ \mathcal{L}_{L1}(G) = \mathbb{E}_{x,y,z}[\|y - G(x, z)\|_1] $$

### 4.3. Total Generator objective
$$ G^* = \arg \min_G \max_D \mathcal{L}_{GAN}(G, D) + \lambda \mathcal{L}_{L1}(G) $$
*   **$\lambda$ (Lambda)**: A weight to balance the two losses. typically $\lambda=100$. This prevents the GAN from hallucinating too wildly by anchoring it to the ground truth.

---

## 5. Training Strategy for S2S

1.  **Phase 1: Warm Start (U-Net Only)**
    *   Train the Generator for e.g., 50 epochs using **only $\mathcal{L}_{L1}$ (MSE/MAE)**.
    *   This establishes a stable baseline and prevents "Mode Collapse" early on.
    *   The model will learn the mean climate patterns but look "blurry".

2.  **Phase 2: Adversarial Fine-Tuning**
    *   Turn on the Discriminator.
    *   Train both networks together.
    *   The Discriminator will penalize the "blurry" predictions, forcing the U-Net to add realistic texture and extremes.

3.  **Regularization**
    *   **Dropout**: Keep dropout active even during test time (Monte Carlo Dropout) if probabilistic quantification is needed.
    *   **Data Augmentation**: Random rotations/flips are **NOT recommended** for weather data as North/South relationships matter (physics). Small translations or noise addition might be acceptable.
